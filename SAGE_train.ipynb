{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask RCNN sequentially so that one can train starting with synthetic data, then retrain models on manual segmentations for better performance. \n",
    "\n",
    "Note that work has been adapted and extends upon the \"train_shapes\" sample from matterport's Mask RCNN release.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 17:00:17.501388: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-21 17:00:17.501423: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-21 17:00:17.501458: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT DIR: /home/timd/Desktop/SAGE\n",
      "Pretrained models dir: /home/timd/Desktop/SAGE/pretrained_models\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "sys.prefix: /home/timd/micromamba/envs/maskrcnn-tf2\n",
      "sys.executable: /home/timd/micromamba/envs/maskrcnn-tf2/bin/python\n",
      "sys.path: ['/home/timd/micromamba/envs/maskrcnn-tf2/lib/python310.zip', '/home/timd/micromamba/envs/maskrcnn-tf2/lib/python3.10', '/home/timd/micromamba/envs/maskrcnn-tf2/lib/python3.10/lib-dynload', '', '/home/timd/.local/lib/python3.10/site-packages', '/home/timd/micromamba/envs/maskrcnn-tf2/lib/python3.10/site-packages', '/home/timd/Desktop/maskrcnn', '/home/timd/.local/lib/python3.10/site-packages/IPython/extensions', '/home/timd/.ipython', '/home/timd/Desktop/SAGE', '/home/timd/Desktop']\n",
      "mrcnn directory: /home/timd/Desktop/SAGE/mrcnn\n",
      "Path to model.py: /home/timd/Desktop/SAGE/mrcnn/model.py\n",
      "MODEL DIRECTORY: /home/timd/Desktop/SAGE/logs\n",
      "Pretrained models dir: /home/timd/Desktop/SAGE/pretrained_models\n",
      "Results DIR: /home/timd/Desktop/SAGE/Results\n",
      "COCO MODEL PATH: /home/timd/Desktop/SAGE/mask_rcnn_coco.h5\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#TODO - look at creating some sort of __init__ file, \n",
    "#       so some of these imports dont have to be shown every time\n",
    "\n",
    "import os\n",
    "\n",
    "# Set which GPU to use dynamically (e.g., \"4\" for GPU 4)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses WARNING and INFO logs, shows only ERRORs\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Must be before importing TensorFlow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Model.state_updates.*\")\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output, display\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../SAGE\")\n",
    "\n",
    "print(\"ROOT DIR:\", ROOT_DIR)\n",
    "\n",
    "\n",
    "#Pretrained models folder, where models already trained are stored\n",
    "PRETRAIN_DIR = os.path.join(ROOT_DIR,\"pretrained_models\")\n",
    "print(\"Pretrained models dir:\", PRETRAIN_DIR)\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "\n",
    "\n",
    "from mrcnn.callbacks import MeanAveragePrecisionCallback\n",
    "\n",
    "\n",
    "\n",
    "from mrcnn.callbacks import TrainingLogger\n",
    "from mrcnn.utils import print_verbose\n",
    "\n",
    "\n",
    "\n",
    "print(\"sys.prefix:\",sys.prefix)\n",
    "print(\"sys.executable:\",sys.executable)\n",
    "print(\"sys.path:\", sys.path)\n",
    "%matplotlib inline \n",
    "\n",
    "mrcnn_dir = os.path.dirname(modellib.__file__)\n",
    "model_file_path = os.path.join(mrcnn_dir,'model.py')\n",
    "print(\"mrcnn directory:\",mrcnn_dir)\n",
    "print(\"Path to model.py:\", model_file_path)\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "print(\"MODEL DIRECTORY:\", MODEL_DIR)\n",
    "\n",
    "#Pretrained models folder, where models already trained are stored\n",
    "PRETRAIN_DIR = os.path.join(ROOT_DIR,\"pretrained_models\")\n",
    "print(\"Pretrained models dir:\", PRETRAIN_DIR)\n",
    "\n",
    "\n",
    "Results_DIR = os.path.join(ROOT_DIR, \"Results\")\n",
    "print(\"Results DIR:\", Results_DIR)\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "print(\"COCO MODEL PATH:\", COCO_MODEL_PATH)\n",
    "\n",
    "\n",
    "#import tensorboard stuff\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - figure out if I should create a .py script wth default sage config or what?\n",
    "class SAGEConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"SAGE\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1 #+ 1  # background + particle + cluster \n",
    "\n",
    "  # Input image resizing\n",
    "    # Generally, use the \"square\" resizing mode for training and predicting\n",
    "    # and it should work well in most cases. In this mode, images are scaled\n",
    "    # up such that the small side is = IMAGE_MIN_DIM, but ensuring that the\n",
    "    # scaling doesn't make the long side > IMAGE_MAX_DIM. Then the image is\n",
    "    # padded with zeros to make it a square so multiple images can be put\n",
    "    # in one batch.\n",
    "    # Available resizing modes:\n",
    "    # none:   No resizing or padding. Return the image unchanged.\n",
    "    # square: Resize and pad with zeros to get a square image\n",
    "    #         of size [max_dim, max_dim].\n",
    "    # pad64:  Pads width and height with zeros to make them multiples of 64.\n",
    "    #         If IMAGE_MIN_DIM or IMAGE_MIN_SCALE are not None, then it scales\n",
    "    #         up before padding. IMAGE_MAX_DIM is ignored in this mode.\n",
    "    #         The multiple of 64 is needed to ensure smooth scaling of feature\n",
    "    #         maps up and down the 6 levels of the FPN pyramid (2**6=64).\n",
    "    # crop:   Picks random crops from the image. First, scales the image based\n",
    "    #         on IMAGE_MIN_DIM and IMAGE_MIN_SCALE, then picks a random crop of\n",
    "    #         size IMAGE_MIN_DIM x IMAGE_MIN_DIM. Can be used in training only.\n",
    "    #         IMAGE_MAX_DIM is not used in this mode.\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 1024\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    # Minimum scaling ratio. Checked after MIN_IMAGE_DIM and can force further\n",
    "    # up scaling. For example, if set to 2 then images are scaled up to double\n",
    "    # the width and height, or more, even if MIN_IMAGE_DIM doesn't require it.\n",
    "    # However, in 'square' mode, it can be overruled by IMAGE_MAX_DIM.\n",
    "    IMAGE_MIN_SCALE = 0\n",
    "    # Number of color channels per image. RGB = 3, grayscale = 1, RGB-D = 4\n",
    "    # Changing this requires other changes in the code. See the WIKI for more\n",
    "    # details: https://github.com/matterport/Mask_RCNN/wiki\n",
    "    IMAGE_CHANNEL_COUNT = 3 #images are grayscale(8bit) so may need to change to 1\n",
    "    \n",
    "    MEAN_PIXEL = np.array([123.7, 116.8, 103.9]) #may need to change to one value for grayscale\n",
    "\n",
    "    # Default \n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256,512) #(16,32,64,128,256)#  # anchor side in pixels\n",
    "                #opt to change to smaller values to recognize smaller particles as well\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 256\n",
    "        #increase from 128 to 256 to allow attempt more \n",
    "    DETECTION_MAX_INSTANCES = 200 #increase from 100 to 200\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH =76 # 76 for 200 #20 for 60 #188 for 750\n",
    "                    \n",
    "    #non-maximum suppression threshold for detection\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 25#num of validation images/batch size\n",
    "    \n",
    "    #EARLY STOPPING\n",
    "    EARLY_STOPPING_MONITOR = 'val_loss'\n",
    "    EARLY_STOPPING_PATIENCE = 10 #number of epochs with no improvement required to stop\n",
    "    ES_RESTORE_BEST_WEIGHTS =True\n",
    "    ES_MODE= \"min\"\n",
    "    ES_VERBOSE = 0\n",
    "    \n",
    "config = SAGEConfig()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets:\n",
    "\n",
    "Here, load the image sets that will be used for training and validation. Multiple can be loaded to facilitate easy access and transfer learning. We load them using an extended dataset class called SAGE_Dataset.\n",
    "\n",
    "We define the datasets to load in a list of tuples, where each tuple contains:\n",
    "1. The dataset name \n",
    "2. A boolean `use_results` indicated whether a results directory should be created\n",
    "\n",
    "In this examples, we will load the following datasets:\n",
    "* `NS40_train`, `NS40_val`: synthetically generate TEM images for training synthetic model (SAGE<sub>0</sub>).\n",
    "* `D1e1_train`, `D1e1_val`: real TEM images annotatated manually for training a second model (SAGE<sub>1</sub>) to fine tune SAGE<sub>0</sub>.\n",
    "* `D2e1_train`, `D2e1_val`: same real TEM images, but annoted by different analysts. Thses datasets are used to train a third model (SAGE<sub>2</sub>) so that it can general better to human variation in manual annotation. \n",
    "\n",
    "Since these datasets are used in training only, we set `use_results=False` so that no results directories are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of tuples: (dataset_name, use_results)\n",
    "\n",
    "datasets_to_load= [\n",
    "    # dataset for synthetic model training\n",
    "    #('NS40_train', False),\n",
    "    #('NS40_val', False),\n",
    "    # datasets for fine tuning with real TEM images\n",
    "    ('D1e1_train', False),\n",
    "    ('D1e1_val', False),\n",
    "    # datasets for fine tuning with real TEM images annotated by different analysts\n",
    "    #('D2e1_train', False),\n",
    "    #('D2e1_val', False),\n",
    "]\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "#loop through list, loading each dataset\n",
    "for idx, (name, use_results) in enumerate(datasets_to_load, start=1):\n",
    "    clear_output(wait=True)\n",
    "    pbar_datasets = tqdm(total=len(datasets_to_load), desc=\"Loading datasets\", dynamic_ncols=True, position=0, leave=True, initial=idx-1, bar_format=\"{l_bar}{bar} {n_fmt}/{total_fmt}\")\n",
    "    datasets[name] = utils.load_and_register_dataset(name,ROOT_DIR, Results_DIR, create_dirs=use_results)\n",
    "    pbar_datasets.update(1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can double check that masks are correctly assigned for each dataset/. For each dataset, it loads the first image and retreives the masks and class ID's, displaying them using `visualize.display_top_masks`. \n",
    "\n",
    "If there are multiple classes (separated by folders in each dataset's directory), the masks for each class will show as well. This helps catch any masks assigned to the wrong image or class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, dataset in datasets.items():\n",
    "    print(f\"\\n--- Dataset: {name} ---\")\n",
    "    if len(dataset.image_ids) ==0: \n",
    "        print(\"No images loaded\")\n",
    "        continue\n",
    "    image_id = dataset.image_ids[0]\n",
    "    print(f\"Image ID:{image_id}\")\n",
    "    \n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    \n",
    "    print(f\"Mask shape for Image ID {image_id}: {mask.shape}\")\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Procedure\n",
    "\n",
    "To train a model we follow the following steps:\n",
    "* 1. Model Initalization\n",
    "* 2. Select Datasets\n",
    "* 3. Define custom callbacks\n",
    "* 4. Define training schedule and train\n",
    "\n",
    "## 1. Model Initialization \n",
    "\n",
    "Now we will create and train our first model, trained on the synthetic images (`NS40_train`, `NS40_val`). \n",
    "\n",
    "First, we create a Mask R-CNN mdoel in training mode and specify which weights to start with.\n",
    "\n",
    "\n",
    "For our SAGE<sub>0</sub> model, we will choose COCO weights (`init_with=coco`) as starting weights. \n",
    "\n",
    "If we wanted to use a previously trained model as a starting point (like for SAGE<sub>1</sub> or SAGE<sub>2</sub>), we can load either the last model trained (`init_with=last`), or specify a path (`init_with=manual`, `manual_path=path/to/model.h5`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO-remove DATA_DIR for actual push\n",
    "DATA_DIR = os.path.abspath(os.path.join(ROOT_DIR, \"../../Data/logs\"))\n",
    "print(\"DATA DIRECTORY:\", DATA_DIR)\n",
    "\n",
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", \n",
    "                          config=config,\n",
    "                          model_dir=DATA_DIR #switch to MODEL_DIR for push\n",
    "                          )\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"manual\"  # imagenet, coco, last, or manual \n",
    "\n",
    "#if you want to give it a specific path to train from:\n",
    "manual_path = os.path.join(PRETRAIN_DIR, \"SAGE_0/SAGE_0.h5\") #pretrained directory holds models provided in work. \n",
    "# or manual_path = os.path.join(logs, \"model_folder/model_epoch.h5\") \n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with ==\"manual\":\n",
    "    #load the weights from specified path\n",
    "    model.load_weights(manual_path, by_name=True)\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our model, we need to define the training/validation datasets, any custom callbacks, and the phases (stages) we want to train our model with.\n",
    "\n",
    "\n",
    "## 2. Select Datasets:\n",
    "\n",
    "First, we will choose the datasets for training and validation from the sets loaded previousy, using `datasets.get('Dataset_name', None)`. If needed, we can check which sets are loaded and available for use using `print_loaded_datasets(datasets)`.\n",
    "\n",
    "We can also adjust the number of training and validation steps per epoch (`STEPS_PER_EPOCH` and `VALIDATION_STEPS`) based on dataset size and batch size if desired.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_loaded_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------Define datasets---------------------------\n",
    "\n",
    "dataset_train = datasets.get('D1e1_train', None) \n",
    "dataset_val = datasets.get('D1e1_val', None)\n",
    "\n",
    "#Adjust step sizes based on batch size\n",
    "config.STEPS_PER_EPOCH = math.ceil(len(dataset_train.image_ids) / config.BATCH_SIZE)\n",
    "config.VALIDATION_STEPS = math.ceil(len(dataset_val.image_ids) / config.BATCH_SIZE)\n",
    "\n",
    "config.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define custom callbacks\n",
    "\n",
    "Next, we will load any custom callbacks, either by writing in a new class of type `tf.keras.callbacks.CALLBACK` or by calling any custom callbacks stored in the `callbacks.py` script. We have two custom callbacks we will be utilizing:\n",
    "\n",
    "`1. MeanAveragePrecisionCallback()`\n",
    "This calculates mAP (both VOC mAP @0.5 IoU and COCO style mAP) of an epoch against the validation dataset. \n",
    "\n",
    "Key inputs:\n",
    "* `train_model`: model being trained\n",
    "* `inference_model`: instance of model in inference mode (must create instance with batch size of 1)\n",
    "* `dataset`: dataset to run mAP calculations on (validation datset) \n",
    "* `dataset_limit`: applies a maximum count of images to calculate mAP on (will use a random subset if dataset has more than maximum count)\n",
    "* `calculate_map_at_every_X_epoch`: controls control how often mAP is calculated (default of 5)\n",
    "\n",
    "`2. TrainingLogger()`\n",
    "\n",
    "Logs training configuration, tracks statistics for each epoch and stage, and stores losses and mAP values\n",
    "\n",
    "Key inputs:\n",
    "* `train_model`: model being trained\n",
    "* `log_dir`: location to save log files (usually model.log_dir)d\n",
    "* `dataset_train`, `dataset_val`: datasets used for training and validation\n",
    "* `init_with`: passes the starting weights used to initialize model\n",
    "* `metric_log_cats`: what metrics or loss you want logged to csv file (`mAP`, `loss`, `general`, `all`). \n",
    "\n",
    "The logging categories for saving to csv (`metric_log_cats`) include the following metrics:\n",
    "* `mAP`: val_AP50 and val_mAP_coco\n",
    "* `loss`: loss and val_loss\n",
    "* `general`: loss, val_loss, val_AP50, and val_MAP_coco\n",
    "* `all`: all losses and mAP values \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Custom Callbacks-----------------------\n",
    "\n",
    "#create a model instance for inference (to be used in mAP callback)\n",
    "class _InfConfig(Config):\n",
    "    NAME=\"SAGE\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    NUM_CLASSES = 1 + 1  # background + particle + cluster\n",
    "\n",
    "model_inference = modellib.MaskRCNN(mode=\"inference\", config=_InfConfig(),\n",
    "                                    model_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "#define mAP callback (full class in mrcnn.callbacks.py)\n",
    "# ----- can control how often mAP is calculated with \"calculate_map_at_every_X_epoch\"\n",
    "mean_average_precision_callback = MeanAveragePrecisionCallback(model, model_inference, dataset_val, \n",
    "                                                            calculate_map_at_every_X_epoch=1, #how often to calculate mAP (after epoch 3)\n",
    "                                                            dataset_limit=50, #option to limit dataset size if validation set is quite large\n",
    "                                                            verbose=1)\n",
    "\n",
    "#allows for config and logging of key training parameters\n",
    "training_logger = TrainingLogger(model, model.log_dir, \n",
    "                                dataset_train, dataset_val,\n",
    "                                init_with=init_with, #initial weights, passed from earlier\n",
    "                                manual_weights_path=manual_path if init_with == \"manual\" else None,\n",
    "                                metric_log_cats=\"general\",\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define training schedule and train\n",
    "We define the training schedule as a list of stages. Each stage specifies:\n",
    "* `name`: which layers to train (e.g. `heads` or `all`) -> passes to `layers` argument in `train()`.\n",
    "* `epochs`: the maximum number of epochs to run in that stage -> passes to `epochs` argument in `train()`. \n",
    "\n",
    "In this example, SAGE uses two stages:\n",
    "\n",
    "\n",
    "* 1. Heads only -> Freeze the backbone and train only the randomly initialized head layers (i.e., the ones not initialized with COCO or other pre-trained weights). This is done by passing `layers=\"heads\"` to the `train()` function from the training stage list. \n",
    "\n",
    "\n",
    "\n",
    "* 2. All layers -> Fine-tune the entire network, including the backbone, by passing `layers=\"all\"` from training stage list. \n",
    "\n",
    "\n",
    "A loop then iterates over each stage defined in the training schedule, training the model stage by stage according to the layers and epochs defined in the list. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#define each stage and max epochs. These will be passed in to train() to define the layers trained in each stage, as well as the max epochs of each stage\n",
    "train_schedule = [\n",
    "    {\"name\": \"heads\", \"epochs\": 100, \"learning_rate\": config.LEARNING_RATE},\n",
    "    {\"name\": \"all\", \"epochs\": 100, \"learning_rate\": config.LEARNING_RATE/10}\n",
    "]\n",
    "\n",
    "total_epochs = sum(stage[\"epochs\"] for stage in train_schedule)\n",
    "cumulative_epochs = 0\n",
    "\n",
    "#loop through stages defined in \"stages\" list:\n",
    "for stage in train_schedule:\n",
    "    stage_name = stage[\"name\"]\n",
    "    stage_epochs = stage[\"epochs\"]\n",
    "\n",
    "    training_logger.stage_name = stage_name\n",
    "    training_logger.scheduled_epochs = stage_epochs\n",
    "    \n",
    "    #start training\n",
    "    model.train(dataset_train,dataset_val, \n",
    "            learning_rate=stage['learning_rate'], \n",
    "            epochs=cumulative_epochs + stage_epochs, \n",
    "            layers=stage_name, custom_callbacks=[mean_average_precision_callback, training_logger])\n",
    "    \n",
    "    cumulative_epochs += stage_epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning on Manual Images \n",
    "\n",
    "After the SAGE<sub>0</sub> is trained, we can use the final weights of that model to initialize a new model that will train on manually annotated real TEM images to fine-tune performance. \n",
    "\n",
    "This follows the same training process as before, just with different starting weights and datasets. \n",
    "\n",
    "By starting with the weights of the last model `init_with=last` and training on `D1e1_train` and `D1e1_val`, we create SAGE<sub>1</sub>.\n",
    "\n",
    "This process is then repeated using `D2e1_train` and `D2e1_val` to create our final model, SAGE<sub>2</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- Create NEW model in training mode ------------\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "#--------Load starting weights (from either last model or a defined path)\n",
    "init_with = \"last\"  # last or manual\n",
    "manual_path\n",
    "\n",
    "if init_with ==\"manual\":\n",
    "    #load the weights from specified path\n",
    "    model.load_weights(manual_path, by_name=True)\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)\n",
    "\n",
    "#--------Assign new train/val datasets---------\n",
    "dataset_train = datasets.get('D1e1_train', None)\n",
    "dataset_val = datasets.get('D1e1_val', None)\n",
    "\n",
    "#Adjust step sizes based on batch size\n",
    "config.STEPS_PER_EPOCH = math.ceil(len(dataset_train.image_ids) / config.BATCH_SIZE)\n",
    "config.VALIDATION_STEPS = math.ceil(len(dataset_val.image_ids) / config.BATCH_SIZE)\n",
    "\n",
    "#------------Redefine Custom Callbacks-----------------------\n",
    "\n",
    "#create a model instance for inference (to be used in mAP callback)\n",
    "class _InfConfig(Config):\n",
    "    NAME=\"SAGE\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    NUM_CLASSES = 1 + 1  # background + particle + cluster\n",
    "\n",
    "model_inference = modellib.MaskRCNN(mode=\"inference\", config=_InfConfig(),\n",
    "                                    model_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "#define mAP callback (full class in mrcnn.callbacks.py)\n",
    "# ----- can control how often mAP is calculated with \"calculate_map_at_every_X_epoch\"\n",
    "mean_average_precision_callback = MeanAveragePrecisionCallback(model, model_inference, dataset_val, \n",
    "                                                            calculate_map_at_every_X_epoch=1, #how often to calculate mAP (after epoch 3)\n",
    "                                                            dataset_limit=50, #option to limit dataset size if validation set is quite large\n",
    "                                                            verbose=1)\n",
    "\n",
    "#allows for config and logging of key training parameters\n",
    "training_logger = TrainingLogger(model, model.log_dir, \n",
    "                                dataset_train, dataset_val,\n",
    "                                init_with=init_with, #initial weights, passed from earlier\n",
    "                                manual_weights_path=manual_path if init_with == \"manual\" else None,\n",
    "                                metric_log_cats=\"general\",\n",
    "                                verbose=1)\n",
    "\n",
    "#---Degine new training schedule and train\n",
    "train_schedule = [\n",
    "    {\"name\": \"heads\", \"epochs\": 100, \"learning_rate\": config.LEARNING_RATE},\n",
    "    {\"name\": \"all\", \"epochs\": 100, \"learning_rate\": config.LEARNING_RATE/10}\n",
    "]\n",
    "\n",
    "total_epochs = sum(stage[\"epochs\"] for stage in train_schedule)\n",
    "cumulative_epochs = 0\n",
    "\n",
    "#loop through stages defined in \"stages\" list:\n",
    "for stage in train_schedule:\n",
    "    stage_name = stage[\"name\"]\n",
    "    stage_epochs = stage[\"epochs\"]\n",
    "\n",
    "    training_logger.stage_name = stage_name\n",
    "    training_logger.scheduled_epochs = stage_epochs\n",
    "    \n",
    "    #start training\n",
    "    model.train(dataset_train,dataset_val, \n",
    "            learning_rate=stage['learning_rate'], \n",
    "            epochs=cumulative_epochs + stage_epochs, \n",
    "            layers=stage_name, custom_callbacks=[mean_average_precision_callback, training_logger])\n",
    "    \n",
    "    cumulative_epochs += stage_epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "#            learning_rate=config.LEARNING_RATE, \n",
    "#            epochs=100, \n",
    "#            layers='heads')\n",
    "\n",
    "#get epoch that it stopped at\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=2, \n",
    "            layers='heads',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "  #          learning_rate=config.LEARNING_RATE / 5, #changed to /5\n",
    "   #         epochs=200, \n",
    "    #        layers=\"all\")\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10, #changed to /5\n",
    "            epochs=4, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = model.find_last()\n",
    "print(name)\n",
    "model_name=name.partition('/logs/')[2]\n",
    "print(model_name)\n",
    "folder_name = model_name.split(os.sep)[0]\n",
    "print(folder_name)\n",
    "\n",
    "save_displayed_config(config,log_dir = path, train_path = dataset_train.particle_masks_dir, val_path =dataset_val.particle_masks_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we repeat the same process with the 2nd set of manual segmentations, D2e1_train, and D2e1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to give it a specific path to train from:\n",
    "manual_path = os.path.join(DATA_DIR, \"logs/coco_M1e1_part/mask_rcnn_spectra_0034.h5\")\n",
    "\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "\n",
    "if init_with ==\"manual\":\n",
    "    #load the weights from specified path\n",
    "    model.load_weights(manual_path, by_name=True)\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loaded_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "#            learning_rate=config.LEARNING_RATE, \n",
    "#            epochs=100, \n",
    "#            layers='heads')\n",
    "\n",
    "#get epoch that it stopped at\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=100, \n",
    "            layers='heads',\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "  #          learning_rate=config.LEARNING_RATE / 5, #changed to /5\n",
    "   #         epochs=200, \n",
    "    #        layers=\"all\")\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10, #changed to /5\n",
    "            epochs=200, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = model.find_last()\n",
    "print(name)\n",
    "model_name=name.partition('/logs/')[2]\n",
    "print(model_name)\n",
    "folder_name = model_name.split(os.sep)[0]\n",
    "print(folder_name)\n",
    "\n",
    "save_displayed_config(config,log_dir = path, train_path = dataset_train.particle_masks_dir, val_path =dataset_val.particle_masks_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskrcnn-tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
